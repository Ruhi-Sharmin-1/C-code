{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crossvalidation_XGBoost.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0iN/5MbJOKfT6yqfaTN/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruhi-Sharmin-1/C-code/blob/main/crossvalidation_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k-q5M42RHXY"
      },
      "outputs": [],
      "source": [
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "#from sklearn.svm import SVC\n",
        "from scipy.io import savemat\n",
        "from scipy.io import loadmat\n",
        "import timeit\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp-5S5BBRYiN",
        "outputId": "1c37999e-8c88-4fc5-e00e-bb038e1705e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaddir_data=F\"/content/gdrive/My Drive/ml-ruhi/\"\n",
        "\n",
        "data = loadmat(loaddir_data + 'challenge_training2017_cases_normal_ecg_corr_metrics.mat',squeeze_me=True)\n",
        "training_normal_features = data['all_corr_metrics'][:,:]\n",
        "n_training_normal = np.shape(training_normal_features)[0]\n",
        "\n",
        "data = loadmat(loaddir_data + 'challenge_training2017_cases_afib_ecg_corr_metrics.mat',squeeze_me=True)\n",
        "training_afib_features = data['all_corr_metrics'][:,:]\n",
        "n_training_afib = np.shape(training_afib_features)[0]\n",
        "\n",
        "data = loadmat(loaddir_data + 'challenge_training2017_cases_noisy_ecg_corr_metrics.mat',squeeze_me=True)\n",
        "training_noisy_features = data['all_corr_metrics'][:,:]\n",
        "n_training_noisy = np.shape(training_noisy_features)[0]\n",
        "\n",
        "data = loadmat(loaddir_data + 'challenge_training2017_cases_other_ecg_corr_metrics.mat',squeeze_me=True)\n",
        "training_other_features = data['all_corr_metrics'][:,:]\n",
        "n_training_other = np.shape(training_other_features)[0]"
      ],
      "metadata": {
        "id": "QcmCQUMzRg_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5)\n",
        "#k=5-fold"
      ],
      "metadata": {
        "id": "LYVhcbE0RlnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf.get_n_splits(training_normal_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFPAr8MVSPgh",
        "outputId": "b48a7a1f-b779-4605-fdcf-ee0b618a806d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train-test splitting for normal data type (80-20, so total no of samples divided into 5 groups)\n",
        "k=1\n",
        "for train_index, test_index in kf.split(training_normal_features):\n",
        "  if k==1:\n",
        "    training_normal_features_k1, testing_normal_features_k1=training_normal_features[train_index],training_normal_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==2:\n",
        "    training_normal_features_k2, testing_normal_features_k2=training_normal_features[train_index],training_normal_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==3:\n",
        "    training_normal_features_k3, testing_normal_features_k3=training_normal_features[train_index],training_normal_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==4:\n",
        "    training_normal_features_k4, testing_normal_features_k4=training_normal_features[train_index],training_normal_features[test_index]\n",
        "    k=k+1\n",
        "  else:\n",
        "    training_normal_features_k5, testing_normal_features_k5=training_normal_features[train_index],training_normal_features[test_index]\n"
      ],
      "metadata": {
        "id": "xrnkoGloSW2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf.get_n_splits(training_afib_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7M_PJL3Va0B",
        "outputId": "4e8619e3-ed5f-4754-98c3-19b8b66670eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train-test splitting for afib data type (80-20, so total no of samples divided into 5 groups)\n",
        "k=1\n",
        "for train_index, test_index in kf.split(training_afib_features):\n",
        "  if k==1:\n",
        "    training_afib_features_k1, testing_afib_features_k1=training_afib_features[train_index],training_afib_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==2:\n",
        "    training_afib_features_k2, testing_afib_features_k2=training_afib_features[train_index],training_afib_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==3:\n",
        "    training_afib_features_k3, testing_afib_features_k3=training_afib_features[train_index],training_afib_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==4:\n",
        "    training_afib_features_k4, testing_afib_features_k4=training_afib_features[train_index],training_afib_features[test_index]\n",
        "    k=k+1\n",
        "  else:\n",
        "    training_afib_features_k5, testing_afib_features_k5=training_afib_features[train_index],training_afib_features[test_index]\n"
      ],
      "metadata": {
        "id": "LqCt1nbbVBCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf.get_n_splits(training_noisy_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-qMaXJsWMAr",
        "outputId": "1bd89867-5c65-4008-df4b-0641bfc60be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train-test splitting for noisy data type (80-20, so total no of samples divided into 5 groups)\n",
        "k=1\n",
        "for train_index, test_index in kf.split(training_noisy_features):\n",
        "  if k==1:\n",
        "    training_noisy_features_k1, testing_noisy_features_k1=training_noisy_features[train_index],training_noisy_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==2:\n",
        "    training_noisy_features_k2, testing_noisy_features_k2=training_noisy_features[train_index],training_noisy_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==3:\n",
        "    training_noisy_features_k3, testing_noisy_features_k3=training_noisy_features[train_index],training_noisy_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==4:\n",
        "    training_noisy_features_k4, testing_noisy_features_k4=training_noisy_features[train_index],training_noisy_features[test_index]\n",
        "    k=k+1\n",
        "  else:\n",
        "    training_noisy_features_k5, testing_noisy_features_k5=training_noisy_features[train_index],training_noisy_features[test_index]"
      ],
      "metadata": {
        "id": "uLMcAq6vWZsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf.get_n_splits(training_other_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_DLnQZ7XA0Y",
        "outputId": "b2a16e84-78b5-4425-b5ca-9ce672482863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train-test splitting for other data type (80-20, so total no of samples divided into 5 groups)\n",
        "k=1\n",
        "for train_index, test_index in kf.split(training_other_features):\n",
        "  if k==1:\n",
        "    training_other_features_k1, testing_other_features_k1=training_other_features[train_index],training_other_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==2:\n",
        "    training_other_features_k2, testing_other_features_k2=training_other_features[train_index],training_other_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==3:\n",
        "    training_other_features_k3, testing_other_features_k3=training_other_features[train_index],training_other_features[test_index]\n",
        "    k=k+1\n",
        "  elif k==4:\n",
        "    training_other_features_k4, testing_other_features_k4=training_other_features[train_index],training_other_features[test_index]\n",
        "    k=k+1\n",
        "  else:\n",
        "    training_other_features_k5, testing_other_features_k5=training_other_features[train_index],training_other_features[test_index]"
      ],
      "metadata": {
        "id": "FSpEXkEDXDIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##k==1 (k=1 validation) 1st fold of 5-fold cross val\n",
        "# append the training datasets and learning datasets\n",
        "training_features_k1 = np.concatenate((training_normal_features_k1,training_afib_features_k1,training_noisy_features_k1,training_other_features_k1),axis=0)\n",
        "training_labels_k1 = np.concatenate((np.zeros(np.shape(training_normal_features_k1)[0]),np.ones(np.shape(training_afib_features_k1)[0]),2*(np.ones(np.shape(training_noisy_features_k1)[0])),3*(np.ones(np.shape(training_other_features_k1)[0]))))"
      ],
      "metadata": {
        "id": "Py2_3f1fXmLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# append the testing datasets for k=1 \n",
        "testing_features_k1 = np.concatenate((testing_normal_features_k1,testing_afib_features_k1,testing_noisy_features_k1,testing_other_features_k1),axis=0)\n",
        "testing_labels_k1 = np.concatenate((np.zeros(np.shape(testing_normal_features_k1)[0]),np.ones(np.shape(testing_afib_features_k1)[0]),2*(np.ones(np.shape(testing_noisy_features_k1)[0])),3*(np.ones(np.shape(testing_other_features_k1)[0]))))"
      ],
      "metadata": {
        "id": "zDtKnURMYqZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m4r3DEV3Yo3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to remove NAN values:\n",
        "def nanremove(x, y):\n",
        "  # input x is training_features, y is labels\n",
        "  if np.argwhere(np.isnan(x)).shape[0]==0:\n",
        "    return x,y\n",
        "  else:\n",
        "    l=np.argwhere(np.isnan(x)).shape[0]\n",
        "    u=np.argwhere(np.isnan(x))\n",
        "    \n",
        "    for i in range(l):      \n",
        "      x = np.delete(x, (u[i,0]-i), axis=0)\n",
        "      y = np.delete(y, (u[i,0]-i), axis=0)\n",
        "    return x,y\n",
        "    \n",
        "x_train,y_train=nanremove(training_features_k1, training_labels_k1)"
      ],
      "metadata": {
        "id": "y8Z-PY1GYY_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test,y_test=nanremove(testing_features_k1, testing_labels_k1)"
      ],
      "metadata": {
        "id": "dt2G03f_ZNe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_all = np.concatenate((x_train, y_train.reshape((-1,1))),axis=1)\n",
        "np.random.shuffle(training_all)  #adds randomness\n",
        "training_features = training_all[:,:-1]\n",
        "training_labels = training_all[:,-1]"
      ],
      "metadata": {
        "id": "LoQ4MDqxYhjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
        "#Lets start by importing the required libraries and loading the data:\n",
        "#Import libraries:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "#from sklearn import cross_validation\n",
        "#from sklearn import metrics   #Additional scklearn functions\n",
        "#from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize'] = 12, 4"
      ],
      "metadata": {
        "id": "6BDtT1KyZn8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "max_depth = 10\n",
        "n_estimators = 110\n",
        "\n",
        "bst = xgb.XGBClassifier(max_depth=max_depth, learning_rate=0.0001, n_estimators=n_estimators, slient=True, min_child_weight=1, objective='multi:softmax', gamma=0, reg_alpha=0, reg_lambda=1)\n",
        "bst.fit(training_features, training_labels) #bst=model\n",
        "# Fit the validation data  # model.predict for Y_predict\n",
        "xgb_pred = bst.predict(x_test)  \n",
        "# extracting most confident predictions\n",
        "best_preds = np.round(xgb_pred)"
      ],
      "metadata": {
        "id": "f6cQ2tqNZ48j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "score = f1_score(y_test, best_preds, average='weighted')\n",
        "print('F-Measure: %.3f' % score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF9oi337ao4O",
        "outputId": "219a97af-ec38-4994-9953-e5c5609c79bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Measure: 0.725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, best_preds)\n",
        "accuracy * 100.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRVkcDkFavfk",
        "outputId": "3f3fab4e-79f5-47f5-fad1-a6530439a0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73.29009433962264"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#probabilty values to create ROC curve for k=1\n",
        "#from the code filename: ROC of XGBoost for all 4 ECG classes\n",
        "\n",
        "xgb_pred_proba = bst.predict_proba(x_test)\n",
        "print(y_test)\n",
        "print(xgb_pred_proba)\n",
        "import pandas as pd \n",
        "pd.DataFrame(y_test).to_csv(F\"/content/gdrive/My Drive/ml-ruhi/XGBoost-Y-true-k=1.csv\")\n",
        "pd.DataFrame(xgb_pred_proba).to_csv(F\"/content/gdrive/My Drive/ml-ruhi/XGBoost-Y-pred-k=1.csv\")\n"
      ],
      "metadata": {
        "id": "DHTAqkY_-QTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k==2 (k=2 validation) 2nd fold of 5-fold cross val\n",
        "# append the training datasets and learning datasets\n",
        "training_features_k2 = np.concatenate((training_normal_features_k2,training_afib_features_k2,training_noisy_features_k2,training_other_features_k2),axis=0)\n",
        "training_labels_k2 = np.concatenate((np.zeros(np.shape(training_normal_features_k2)[0]),np.ones(np.shape(training_afib_features_k2)[0]),2*(np.ones(np.shape(training_noisy_features_k2)[0])),3*(np.ones(np.shape(training_other_features_k2)[0]))))\n",
        "\n",
        "testing_features_k2 = np.concatenate((testing_normal_features_k2,testing_afib_features_k2,testing_noisy_features_k2,testing_other_features_k2),axis=0)\n",
        "testing_labels_k2 = np.concatenate((np.zeros(np.shape(testing_normal_features_k2)[0]),np.ones(np.shape(testing_afib_features_k2)[0]),2*(np.ones(np.shape(testing_noisy_features_k2)[0])),3*(np.ones(np.shape(testing_other_features_k2)[0]))))\n",
        "\n",
        "x_train,y_train=nanremove(training_features_k2, training_labels_k2)\n",
        "\n",
        "x_test,y_test=nanremove(testing_features_k2, testing_labels_k2)\n",
        "\n",
        "training_all = np.concatenate((x_train, y_train.reshape((-1,1))),axis=1)\n",
        "np.random.shuffle(training_all)  #adds randomness\n",
        "training_features = training_all[:,:-1]\n",
        "training_labels = training_all[:,-1]\n",
        "\n",
        "bst = xgb.XGBClassifier(max_depth=max_depth, learning_rate=0.0001, n_estimators=n_estimators, slient=True, min_child_weight=1, objective='multi:softmax', gamma=0, reg_alpha=0, reg_lambda=1)\n",
        "bst.fit(training_features, training_labels) #bst=model\n",
        "# Fit the validation data  # model.predict for Y_predict\n",
        "xgb_pred = bst.predict(x_test)  \n",
        "# extracting most confident predictions\n",
        "best_preds = np.round(xgb_pred)"
      ],
      "metadata": {
        "id": "COCN_G3Kax-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "score = f1_score(y_test, best_preds, average='weighted')\n",
        "print('F-Measure: %.3f' % score)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, best_preds)\n",
        "accuracy * 100.0\n",
        "\n",
        "#from the code filename: ROC of XGBoost for all 4 ECG classes\n",
        "#probabilty values to create ROC curve for k=2\n",
        "xgb_pred_proba = bst.predict_proba(x_test)\n",
        "print(y_test)\n",
        "print(xgb_pred_proba)\n",
        "import pandas as pd \n",
        "pd.DataFrame(y_test).to_csv(F\"/content/gdrive/My Drive/ml-ruhi/XGBoost-Y-true-k=2.csv\")\n",
        "pd.DataFrame(xgb_pred_proba).to_csv(F\"/content/gdrive/My Drive/ml-ruhi/XGBoost-Y-pred-k=2.csv\")\n"
      ],
      "metadata": {
        "id": "mVzIpmq3bQAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k==3 (k=3 validation) 3rd fold of 5-fold cross val\n",
        "# append the training datasets and learning datasets\n",
        "training_features_k3 = np.concatenate((training_normal_features_k3,training_afib_features_k3,training_noisy_features_k3,training_other_features_k3),axis=0)\n",
        "training_labels_k3 = np.concatenate((np.zeros(np.shape(training_normal_features_k3)[0]),np.ones(np.shape(training_afib_features_k3)[0]),2*(np.ones(np.shape(training_noisy_features_k3)[0])),3*(np.ones(np.shape(training_other_features_k3)[0]))))\n",
        "\n",
        "testing_features_k3 = np.concatenate((testing_normal_features_k3,testing_afib_features_k3,testing_noisy_features_k3,testing_other_features_k3),axis=0)\n",
        "testing_labels_k3 = np.concatenate((np.zeros(np.shape(testing_normal_features_k3)[0]),np.ones(np.shape(testing_afib_features_k3)[0]),2*(np.ones(np.shape(testing_noisy_features_k3)[0])),3*(np.ones(np.shape(testing_other_features_k3)[0]))))\n",
        "\n",
        "x_train,y_train=nanremove(training_features_k3, training_labels_k3)\n",
        "\n",
        "x_test,y_test=nanremove(testing_features_k3, testing_labels_k3)\n",
        "\n",
        "training_all = np.concatenate((x_train, y_train.reshape((-1,1))),axis=1)\n",
        "np.random.shuffle(training_all)  #adds randomness\n",
        "training_features = training_all[:,:-1]\n",
        "training_labels = training_all[:,-1]\n",
        "\n",
        "bst = xgb.XGBClassifier(max_depth=max_depth, learning_rate=0.0001, n_estimators=n_estimators, slient=True, min_child_weight=1, objective='multi:softmax', gamma=0, reg_alpha=0, reg_lambda=1)\n",
        "bst.fit(training_features, training_labels) #bst=model\n",
        "# Fit the validation data  # model.predict for Y_predict\n",
        "xgb_pred = bst.predict(x_test)  \n",
        "# extracting most confident predictions\n",
        "best_preds = np.round(xgb_pred)"
      ],
      "metadata": {
        "id": "rIA90QvrbWdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "score = f1_score(y_test, best_preds, average='weighted')\n",
        "print('F-Measure: %.3f' % score)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, best_preds)\n",
        "accuracy * 100.0\n",
        "\n",
        "#from the code filename: ROC of XGBoost for all 4 ECG classes\n",
        "#probabilty values to create ROC curve for k=3\n",
        "xgb_pred_proba = bst.predict_proba(x_test)\n",
        "print(y_test)\n",
        "print(xgb_pred_proba)\n",
        "import pandas as pd \n",
        "pd.DataFrame(y_test).to_csv(F\"/content/gdrive/My Drive/ml-ruhi/XGBoost-Y-true-k=3.csv\")\n",
        "pd.DataFrame(xgb_pred_proba).to_csv(F\"/content/gdrive/My Drive/ml-ruhi/XGBoost-Y-pred-k=3.csv\")\n"
      ],
      "metadata": {
        "id": "nZ-Xj8Dl_vlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k==4 (k=4 validation) 4th fold of 5-fold cross val\n",
        "# append the training datasets and learning datasets\n",
        "training_features_k4 = np.concatenate((training_normal_features_k4,training_afib_features_k4,training_noisy_features_k4,training_other_features_k4),axis=0)\n",
        "training_labels_k4 = np.concatenate((np.zeros(np.shape(training_normal_features_k4)[0]),np.ones(np.shape(training_afib_features_k4)[0]),2*(np.ones(np.shape(training_noisy_features_k4)[0])),3*(np.ones(np.shape(training_other_features_k4)[0]))))\n",
        "\n",
        "testing_features_k4 = np.concatenate((testing_normal_features_k4,testing_afib_features_k4,testing_noisy_features_k4,testing_other_features_k4),axis=0)\n",
        "testing_labels_k4 = np.concatenate((np.zeros(np.shape(testing_normal_features_k4)[0]),np.ones(np.shape(testing_afib_features_k4)[0]),2*(np.ones(np.shape(testing_noisy_features_k4)[0])),3*(np.ones(np.shape(testing_other_features_k4)[0]))))\n",
        "\n",
        "x_train,y_train=nanremove(training_features_k4, training_labels_k4)\n",
        "\n",
        "x_test,y_test=nanremove(testing_features_k4, testing_labels_k4)\n",
        "\n",
        "training_all = np.concatenate((x_train, y_train.reshape((-1,1))),axis=1)\n",
        "np.random.shuffle(training_all)  #adds randomness\n",
        "training_features = training_all[:,:-1]\n",
        "training_labels = training_all[:,-1]\n",
        "\n",
        "bst = xgb.XGBClassifier(max_depth=max_depth, learning_rate=0.0001, n_estimators=n_estimators, slient=True, min_child_weight=1, objective='multi:softmax', gamma=0, reg_alpha=0, reg_lambda=1)\n",
        "bst.fit(training_features, training_labels) #bst=model\n",
        "# Fit the validation data  # model.predict for Y_predict\n",
        "xgb_pred = bst.predict(x_test)  \n",
        "# extracting most confident predictions\n",
        "best_preds = np.round(xgb_pred)"
      ],
      "metadata": {
        "id": "RYE5oafYbY9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "score = f1_score(y_test, best_preds, average='weighted')\n",
        "print('F-Measure: %.3f' % score)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, best_preds)\n",
        "accuracy * 100.0\n",
        "\n",
        "#from the code filename: ROC of XGBoost for all 4 ECG classes\n",
        "#probabilty values to create ROC curve for k=4\n",
        "xgb_pred_proba = bst.predict_proba(x_test)\n",
        "print(y_test)\n",
        "print(xgb_pred_proba)\n",
        "import pandas as pd \n",
        "pd.DataFrame(y_test).to_csv(F\"/content/gdrive/My Drive/ml-ruhi/XGBoost-Y-true-k=4.csv\")\n",
        "pd.DataFrame(xgb_pred_proba).to_csv(F\"/content/gdrive/My Drive/ml-ruhi/XGBoost-Y-pred-k=4.csv\")\n"
      ],
      "metadata": {
        "id": "AqUK1YTM_xKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#k==5 (k=5 validation) 5th fold of 5-fold cross val\n",
        "# append the training datasets and learning datasets\n",
        "training_features_k5 = np.concatenate((training_normal_features_k5,training_afib_features_k5,training_noisy_features_k5,training_other_features_k5),axis=0)\n",
        "training_labels_k5 = np.concatenate((np.zeros(np.shape(training_normal_features_k5)[0]),np.ones(np.shape(training_afib_features_k5)[0]),2*(np.ones(np.shape(training_noisy_features_k5)[0])),3*(np.ones(np.shape(training_other_features_k5)[0]))))\n",
        "\n",
        "testing_features_k5 = np.concatenate((testing_normal_features_k1,testing_afib_features_k1,testing_noisy_features_k1,testing_other_features_k1),axis=0)\n",
        "testing_labels_k5 = np.concatenate((np.zeros(np.shape(testing_normal_features_k5)[0]),np.ones(np.shape(testing_afib_features_k5)[0]),2*(np.ones(np.shape(testing_noisy_features_k5)[0])),3*(np.ones(np.shape(testing_other_features_k5)[0]))))\n",
        "\n",
        "x_train,y_train=nanremove(training_features_k5, training_labels_k5)\n",
        "\n",
        "x_test,y_test=nanremove(testing_features_k5, testing_labels_k5)\n",
        "\n",
        "training_all = np.concatenate((x_train, y_train.reshape((-1,1))),axis=1)\n",
        "np.random.shuffle(training_all)  #adds randomness\n",
        "training_features = training_all[:,:-1]\n",
        "training_labels = training_all[:,-1]\n",
        "\n",
        "bst = xgb.XGBClassifier(max_depth=max_depth, learning_rate=0.0001, n_estimators=n_estimators, slient=True, min_child_weight=1, objective='multi:softmax', gamma=0, reg_alpha=0, reg_lambda=1)\n",
        "bst.fit(training_features, training_labels) #bst=model\n",
        "# Fit the validation data  # model.predict for Y_predict\n",
        "xgb_pred = bst.predict(x_test)  \n",
        "# extracting most confident predictions\n",
        "best_preds = np.round(xgb_pred)\n"
      ],
      "metadata": {
        "id": "Zzglc3fdbZaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "score = f1_score(y_test, best_preds, average='weighted')\n",
        "print('F-Measure: %.3f' % score)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, best_preds)\n",
        "accuracy * 100.0\n",
        "\n",
        "#from the code filename: ROC of XGBoost for all 4 ECG classes\n",
        "#probabilty values to create ROC curve for k=5\n",
        "xgb_pred_proba = bst.predict_proba(x_test)\n",
        "print(y_test)\n",
        "print(xgb_pred_proba)\n",
        "import pandas as pd \n",
        "pd.DataFrame(y_test).to_csv(F\"/content/gdrive/My Drive/ml-ruhi/XGBoost-Y-true-k=5.csv\")\n",
        "pd.DataFrame(xgb_pred_proba).to_csv(F\"/content/gdrive/My Drive/ml-ruhi/XGBoost-Y-pred-k=5.csv\")\n"
      ],
      "metadata": {
        "id": "Ri86zdtn_ynx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}